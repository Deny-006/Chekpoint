# -*- coding: utf-8 -*-
"""Checkpoint 2 - Data Understanding & Data Preparation - Deny candra kasuma - 2409116024.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R55WpNRFCGmuY_Ih_t9wNqAUtCWsbTcr

**Furniture Price Prediction - Analisis faktor-faktor yang memengaruhi harga furnitur di platform e-commerce guna mendukung strategi harga yang lebih akurat dan kompetitif.**

**SUMBER DATASET:** https://www.kaggle.com/datasets/shawkyelgendy/furniture-price-prediction?resource=download

Dataset ini berisi informasi mengenai berbagai jenis furnitur yang dijual di Jumia.com. Data ini mencakup nama furnitur, kategori atau jenisnya, tautan ke halaman produk, rating pelanggan, opsi pengiriman, status penjualan, dan harga. dataset ini dapat digunakan untuk analisis eksplorasi, studi tren pasar, optimasi harga, serta pemodelan prediktif dalam memperkirakan harga furnitur berdasarkan fitur-fitur yang tersedia.

**LIBRARY**
"""

import pandas as pd

"""**DATA UNDERSTANDING**

**Membaca Data**
"""

df = pd.read_csv("/content/Furniture Price Prediction.csv")

df

"""**Menampilkan Keseluruhan Data**"""

print(df.to_string())

"""**Memeriksa Struktur Data**

1. Menampilkan Informasi dataset
"""

df.info()

"""2. Menampilkan jumalah baris dan kolom dataset"""

df.shape

"""3. Menampilkan tipe data tiap kolom dataset"""

df.dtypes

"""**Memeriksa Statistik Deskriptif**

1. Menampilkan statistik deskriptif
"""

df.describe()

"""2. Menghitung standar deviasi"""

df.std(numeric_only=True)

"""3. Menghitung korelasi antar kolom numerik"""

df.corr(numeric_only=True)

"""**DATA PREPARATION**

**Membaca Data**
"""

df = pd.read_csv("/content/Furniture Price Prediction.csv")

df

"""**Menampilkan Keseluruhan Data**"""

print(df.to_string())

"""**Data Cleaning**

Data cleaning merupakan proses menghapus atau memodifikasi data yang tidak lengkap, duplikat, tidak akurat, dan salah format. Data-data tersebut dihapus atau dimodifikasi untuk memastikan data yang sedang diolah adalah data berkualitas agar dapat menghasilkan keputusan yang lebih akurat.

1. Missing values
"""

print((df.isna().sum() / len(df)) * 100)

"""Melakukan pengecekan nilai kosong pada kolom price"""

df[df['price'].isnull()]

"""Melakukan Imputasi

Di sini kita akan melakukan imputasi pada kolom price dikarenakan data yang hilang pada kolom ini berada di angka 1.95%
"""

df['price'].dropna().describe()

"""Disini berdasarkan hasil analisis statistik, kita dapat menggunakan mean dari kolom price untuk imputasi nilai kosong tersebut"""

df['price'] = df['price'].fillna(df['price'].dropna().mean())

"""2. Duplicated Values

Mengecek apakah ada data yang muncul beberapa kali dalam satu data set.
"""

df[df.duplicated()]

"""Hasil dari kode diatas menunjukkan bahwa tidak ada yang muncul beberapa kali dalam dataset. Maka dari itu tidak perlu melakukan penanganan duplicated values dengan menghapus semua duplikasi

3. Outliers
"""

results = []

cols = df.select_dtypes(include=['float64', 'int64'])

for col in cols:
  q1 = df[col].quantile(0.25)
  q3 = df[col].quantile(0.75)
  iqr = q3 - q1
  lower_bound = q1 - 1.5*iqr
  upper_bound = q3 + 1.5*iqr
  outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
  percent_outliers = (len(outliers)/len(df))*100
  results.append({'Kolom': col, 'Persentase Outliers': percent_outliers})

# Dataframe dari list hasil
results_df = pd.DataFrame(results)
results_df.set_index('Kolom', inplace=True)
results_df = results_df.rename_axis(None, axis=0).rename_axis('Kolom', axis=1)

# Tampilkan dataframe
display(results_df)

"""Hasil dari kode diatas menunjukkan bahwa terdapat nilai yang jauh berbeda pada bagian Rate, Delivery, dan Price. Oleh karena itu diperlukan penanganan lebih lanjut terhadap outliers.

Dikarenakan presentase yang tidak terlalu tinggi maka dapat melakukan imputasi
"""

columns_to_impute = ["rate", "delivery", "price"]

for col in columns_to_impute:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Menggunakan .loc[] agar tidak muncul SettingWithCopyWarning
    df.loc[:, col] = df[col].clip(lower=lower_bound, upper=upper_bound).astype(df[col].dtype)

"""Melakukan pengecekan ulang"""

results = []

cols = df.select_dtypes(include=['float64', 'int64'])

for col in cols:
  q1 = df[col].quantile(0.25)
  q3 = df[col].quantile(0.75)
  iqr = q3 - q1
  lower_bound = q1 - 1.5*iqr
  upper_bound = q3 + 1.5*iqr
  outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
  percent_outliers = (len(outliers)/len(df))*100
  results.append({'Kolom': col, 'Persentase Outliers': percent_outliers})

# Dataframe dari list hasil
results_df = pd.DataFrame(results)
results_df.set_index('Kolom', inplace=True)
results_df = results_df.rename_axis(None, axis=0).rename_axis('Kolom', axis=1)

# Tampilkan dataframe
display(results_df)

"""Hasil dari kode di atas menunjukkan bahwa setelah dilakukan penanganan outliers, tidak ada lagi nilai yang jauh berbeda dalam dataset. Ini berarti proses penyesuaian telah berhasil dilakukan, sehingga data menjadi lebih bersih dan siap untuk analisis lebih lanjut.

4. Inconsisten values
"""

df

"""Hasil dari kode diatas menunjukkan bahwa tidak terdapat Inconsistent Values dalam dataset. Maka dari itu tidak perlu melakukan penanganan terhadap Inconsistent Values.

5. Construct Data
"""

# menambahkan kolom harga ke dalam kategori murah, sedang, dan mahal untuk analisis yang lebih mudah.
df['price_category'] = pd.cut(df['price'], bins=[0, 500, 1500, float('inf')], labels=['low', 'medium', 'high'])

# Menampilkan beberapa data sebagai contoh
print(df[["furniture", "type", "rate", "delivery", "sale", "price", "price_category"]].head())

df

"""6. Data Reduction

Menghapus kolom-kolom yang tidak relevan dengan studi kasus
"""

df = df.drop('url', axis=1)

df